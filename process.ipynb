{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "import geopandas as gp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_width, img_height = 5184, 3888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prev/confidence_data.pickle\", \"rb\") as f:\n",
    "    data = np.array(pickle.load(f))\n",
    "full_dataset = dict((data[i][0], [data[i][3], data[i][4]]) for i in range(data.shape[0]))\n",
    "mask_map = data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geotag(path, mask_path, min_height = 5400):\n",
    "    image = Image.open(path)\n",
    "    image = np.array(image)\n",
    "\n",
    "    # geotagging part\n",
    "    mask = np.zeros([img_height, img_width])\n",
    "    df = gp.read_file(mask_path)\n",
    "    for poly in df['geometry']:\n",
    "        x, y = poly.exterior.coords.xy\n",
    "        polygon = [(x, y) for x, y in zip(x, y)]\n",
    "        img = Image.new('L', (img_width, img_height), 0)\n",
    "        ImageDraw.Draw(img).polygon(polygon, outline=1, fill=1)\n",
    "\n",
    "        poly_mask = np.array(img)\n",
    "        poly_mask = np.reshape(poly_mask, mask.shape)\n",
    "\n",
    "        mask = np.logical_or(mask, poly_mask)\n",
    "\n",
    "\n",
    "    mask = mask.astype(np.float)\n",
    "\n",
    "    # get the image part only, discard the black part\n",
    "    # start_row = -1\n",
    "    # end_row = mask.shape[0]\n",
    "    # for i in range(0, mask.shape[0]):\n",
    "    #     if mask[i].any() > 0 and start_row == -1:\n",
    "    #         start_row = i\n",
    "    #     elif mask[i].any() == 0 and start_row != -1:\n",
    "    #         end_row = i + 1\n",
    "    #         break\n",
    "    for i in range(0, mask.shape[0]):\n",
    "        if mask[i].any() != 0:\n",
    "            continue\n",
    "        else:\n",
    "            image[i, :, :] = 0 # (image[i, :, :] * 0.3).astype(np.int64)\n",
    "\n",
    "    # if end_row - start_row < min_height:\n",
    "        # min_height = end_row - start_row\n",
    "    # image = image[start_row:end_row, :, :]\n",
    "    # mask = np.stack([mask, mask, mask], axis=2)\n",
    "    # new_img = image * mask\n",
    "    # plt.figure()\n",
    "    # plt.imshow(image)\n",
    "    # save \n",
    "    image = Image.fromarray(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  908\n",
      "Dataset distribution:  [291, 329, 111, 177]\n",
      "\n",
      "Corn dataset size:  395\n",
      "Corn dataset distribution:  [78, 199, 73, 45]\n",
      "\n",
      "Soybean dataset size:  346\n",
      "Soybean dataset distribution:  [171, 84, 17, 74]\n",
      "\n",
      "Other dataset size:  167\n",
      "Other dataset distribution:  [42, 46, 21, 58]\n",
      "\n",
      "                 High tillage  Low tillage  No tillage  Grass  Datasize\n",
      "Full dataset              291          329         111    177       908\n",
      "Corn Dataset               78          199          73     45       395\n",
      "Soybean Dataset           171           84          17     74       346\n",
      "Other Dataset              42           46          21     58       167\n"
     ]
    }
   ],
   "source": [
    "data_size = 0\n",
    "corn_data_size = 0\n",
    "soybean_data_size = 0\n",
    "other_data_size = 0\n",
    "\n",
    "data_distribution = [0, 0, 0, 0]\n",
    "corn_data_distribution = [0, 0, 0, 0]\n",
    "soybean_data_distribution = [0, 0, 0, 0]\n",
    "other_data_distribution = [0, 0, 0, 0]\n",
    "\n",
    "corn_data = {}\n",
    "soybean_data = {}\n",
    "other_data = {}\n",
    "\n",
    "for folders in os.listdir(\"StreetviewImages\"):\n",
    "    for files in os.listdir(\"StreetviewImages/\" + folders):\n",
    "        path = \"StreetviewImages/\" + folders + \"/\" + files\n",
    "        mask_path = \"StreetviewBoundaries/\" + folders + \"/\" + files + \".geojson\"\n",
    "        if os.path.exists(path) and os.path.exists(mask_path) and path in full_dataset.keys() and mask_path in mask_map:\n",
    "            data_size += 1\n",
    "\n",
    "            info = full_dataset[path]\n",
    "            info.append(mask_path)\n",
    "            info.append(files)\n",
    "            data_distribution[info[1]] += 1\n",
    "\n",
    "            if info[0] == 5:\n",
    "                soybean_data_size += 1\n",
    "                soybean_data_distribution[info[1]] += 1\n",
    "                soybean_data[path] = info\n",
    "            elif info[0] == 1:\n",
    "                corn_data_size += 1\n",
    "                corn_data_distribution[info[1]] += 1\n",
    "                corn_data[path] = info\n",
    "            else:\n",
    "                other_data_size += 1\n",
    "                other_data_distribution[info[1]] += 1\n",
    "                other_data[path] = info\n",
    "\n",
    "\n",
    "print(\"Dataset size: \", data_size)\n",
    "print(\"Dataset distribution: \", data_distribution)\n",
    "data_distribution.append(data_size)\n",
    "\n",
    "print(\"\\nCorn dataset size: \", corn_data_size)\n",
    "print(\"Corn dataset distribution: \", corn_data_distribution)\n",
    "corn_data_distribution.append(corn_data_size)\n",
    "\n",
    "print(\"\\nSoybean dataset size: \", soybean_data_size)\n",
    "print(\"Soybean dataset distribution: \", soybean_data_distribution)\n",
    "soybean_data_distribution.append(soybean_data_size)\n",
    "\n",
    "print(\"\\nOther dataset size: \", other_data_size)\n",
    "print(\"Other dataset distribution: \", other_data_distribution)\n",
    "other_data_distribution.append(other_data_size)\n",
    "\n",
    "print()\n",
    "data_table = np.array([data_distribution, corn_data_distribution, soybean_data_distribution, other_data_distribution])\n",
    "\n",
    "dtf = pd.DataFrame(data_table)\n",
    "dtf.index = [\"Full dataset\", \"Corn Dataset\", \"Soybean Dataset\", \"Other Dataset\"]\n",
    "dtf.columns = [\"High tillage\", \"Low tillage\", \"No tillage\", \"Grass\", \"Datasize\"]\n",
    "print(dtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_key = list(corn_data)\n",
    "corn_train, corn_other = train_test_split(corn_key, test_size=0.3)\n",
    "corn_val, corn_test = train_test_split(corn_other, test_size = 0.5)\n",
    "corn_dataset = {\n",
    "    \"train\": corn_train,\n",
    "    \"val\": corn_val,\n",
    "    \"test\": corn_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_key = list(soybean_data)\n",
    "soybean_train, soybean_other = train_test_split(soybean_key, test_size=0.3)\n",
    "soybean_val, soybean_test = train_test_split(soybean_other, test_size = 0.5)\n",
    "soybean_dataset = {\n",
    "    \"train\": soybean_train,\n",
    "    \"val\": soybean_val,\n",
    "    \"test\": soybean_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_image(image_dir, geotagging_dir, phase, path, info):\n",
    "    crop_type, tillage_type, mask_path, file_name = info\n",
    "\n",
    "    image_dir_phase = image_dir + \"/\" + phase\n",
    "    geotagging_dir_phase = geotagging_dir + \"/\" + phase\n",
    "\n",
    "    if not os.path.exists(image_dir_phase):\n",
    "        os.mkdir(image_dir_phase)\n",
    "    \n",
    "    if not os.path.exists(geotagging_dir_phase):\n",
    "        os.mkdir(geotagging_dir_phase)\n",
    "\n",
    "    tillage_dict = {\n",
    "        0: \"/high_tillage/\",\n",
    "        1: \"/low_tillage/\",\n",
    "        2: \"/no_tillage/\",\n",
    "        3: \"/grass/\"\n",
    "    }\n",
    "\n",
    "    image_dir_phase += tillage_dict[tillage_type]\n",
    "    geotagging_dir_phase += tillage_dict[tillage_type]\n",
    "    \n",
    "    if not os.path.exists(geotagging_dir_phase):\n",
    "        os.mkdir(geotagging_dir_phase)\n",
    "    \n",
    "    image_dir_phase += file_name\n",
    "    geotagging_dir_phase += file_name\n",
    "\n",
    "    image = Image.open(path)\n",
    "    geotagging_image = geotag(path, mask_path)\n",
    "\n",
    "    image.save(image_dir_phase)\n",
    "    geotagging_image.save(geotagging_dir_phase) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages(main_dir, type, crop_dataset, crop_data):\n",
    "\n",
    "    dir = main_dir + \"_image/\"\n",
    "    # gdir = main_dir + \"_geotagging/\"\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "\n",
    "    # if not os.path.exists(gdir):\n",
    "    #     os.mkdir(gdir)\n",
    "\n",
    "\n",
    "    image_dir = main_dir + \"_image/\" + type + \"_dataset\"\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.mkdir(image_dir)\n",
    "    else:\n",
    "        print(\"Directory already exists\")\n",
    "        return\n",
    "    # geotagging_dir = main_dir + \"_geotagging/\" + type + \"_dataset\"\n",
    "    # if not os.path.exists(geotagging_dir):\n",
    "    #     os.mkdir(geotagging_dir)\n",
    "\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for phase in [\"train\", \"val\", \"test\"]:\n",
    "        dataset = crop_dataset[phase]\n",
    "        for path in dataset:\n",
    "            info = crop_data[path]\n",
    "            crop_type, tillage_type, mask_path, file_name = info\n",
    "\n",
    "            image_dir_phase = image_dir + \"/\" + phase\n",
    "            # geotagging_dir_phase = geotagging_dir + \"/\" + phase\n",
    "\n",
    "            if not os.path.exists(image_dir_phase):\n",
    "                os.mkdir(image_dir_phase)\n",
    "            \n",
    "            # if not os.path.exists(geotagging_dir_phase):\n",
    "            #     os.mkdir(geotagging_dir_phase)\n",
    "\n",
    "            if info[1] == 0:\n",
    "                image_dir_phase += \"/high_tillage/\"\n",
    "                # geotagging_dir_phase += \"/high_tillage/\"\n",
    "            elif info[1] == 1:\n",
    "                image_dir_phase += \"/low_tillage/\"\n",
    "                # geotagging_dir_phase += \"/low_tillage/\"\n",
    "            elif info[1] == 2:\n",
    "                image_dir_phase += \"/no_tillage/\"\n",
    "                # geotagging_dir_phase += \"/no_tillage/\"\n",
    "            elif info[1] == 3:\n",
    "                image_dir_phase += \"/grass/\"\n",
    "                # geotagging_dir_phase += \"/grass/\"\n",
    "\n",
    "            if not os.path.exists(image_dir_phase):\n",
    "                os.mkdir(image_dir_phase)\n",
    "            \n",
    "            # if not os.path.exists(geotagging_dir_phase):\n",
    "            #     os.mkdir(geotagging_dir_phase)\n",
    "            \n",
    "            image_dir_phase += file_name\n",
    "            # geotagging_dir_phase += file_name\n",
    "\n",
    "            image = Image.open(path)\n",
    "            # geotagging_image = geotag(path, mask_path)\n",
    "\n",
    "            image.save(image_dir_phase)\n",
    "            # geotagging_image.save(geotagging_dir_phase) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "processImages(\"large_drop\", \"corn1\", corn_dataset, corn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processImages(\"large_drop\", \"soybean\", soybean_dataset, soybean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 2)\n",
      "(102, 2)\n"
     ]
    }
   ],
   "source": [
    "with open('./ground_truth_analysis/corn_data.npy', 'rb') as f:\n",
    "    corn_data = np.load(f,allow_pickle=True)\n",
    "\n",
    "with open('./ground_truth_analysis/soybean_data.npy', 'rb') as f:\n",
    "    soybean_data = np.load(f,allow_pickle=True)\n",
    "\n",
    "print(corn_data.shape)\n",
    "print(soybean_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "corn_dataset = dict((corn_data[i][0], corn_data[i][1]) for i in range(corn_data.shape[0]))\n",
    "soybean_dataset = dict((soybean_data[i][0], soybean_data[i][1]) for i in range(soybean_data.shape[0]))\n",
    "\n",
    "print(len(corn_data))\n",
    "print(len(soybean_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  180\n",
      "Dataset distribution:  [0, 29, 87, 64]\n",
      "\n",
      "Corn dataset size:  79\n",
      "Corn dataset distribution:  [0, 4, 50, 25]\n",
      "\n",
      "Soybean dataset size:  101\n",
      "Soybean dataset distribution:  [0, 25, 37, 39]\n",
      "\n",
      "Other dataset size:  0\n",
      "Other dataset distribution:  [0, 0, 0, 0]\n",
      "\n",
      "                 Grass  High tillage  Low tillage  No tillage  Datasize\n",
      "Full dataset         0            29           87          64       180\n",
      "Corn Dataset         0             4           50          25        79\n",
      "Soybean Dataset      0            25           37          39       101\n",
      "Other Dataset        0             0            0           0         0\n"
     ]
    }
   ],
   "source": [
    "data_size = 0\n",
    "corn_data_size = 0\n",
    "soybean_data_size = 0\n",
    "other_data_size = 0\n",
    "\n",
    "data_distribution = [0, 0, 0, 0]\n",
    "corn_data_distribution = [0, 0, 0, 0]\n",
    "soybean_data_distribution = [0, 0, 0, 0]\n",
    "other_data_distribution = [0, 0, 0, 0]\n",
    "\n",
    "corn_data = {}\n",
    "soybean_data = {}\n",
    "other_data = {}\n",
    "\n",
    "\n",
    "for files in os.listdir(\"ground_truth_analysis/ground_truth\"):\n",
    "    path = \"ground_truth_analysis/ground_truth/\" + files\n",
    "    if not os.path.exists(path):\n",
    "        continue\n",
    "\n",
    "    if files in corn_dataset.keys():\n",
    "        data_size += 1\n",
    "\n",
    "        info = corn_dataset[files]\n",
    "        info = [files, info]\n",
    "        data_distribution[info[1]] += 1\n",
    "\n",
    "        corn_data_size += 1\n",
    "        corn_data_distribution[info[1]] += 1\n",
    "        corn_data[files] = info\n",
    "\n",
    "    elif files in soybean_dataset.keys():\n",
    "        data_size += 1\n",
    "\n",
    "        info = soybean_dataset[files]\n",
    "        info = [files, info]\n",
    "        data_distribution[info[1]] += 1\n",
    "\n",
    "        soybean_data_size += 1\n",
    "        soybean_data_distribution[info[1]] += 1\n",
    "        soybean_data[files] = info\n",
    "\n",
    "print(\"Dataset size: \", data_size)\n",
    "print(\"Dataset distribution: \", data_distribution)\n",
    "data_distribution.append(data_size)\n",
    "\n",
    "print(\"\\nCorn dataset size: \", corn_data_size)\n",
    "print(\"Corn dataset distribution: \", corn_data_distribution)\n",
    "corn_data_distribution.append(corn_data_size)\n",
    "\n",
    "print(\"\\nSoybean dataset size: \", soybean_data_size)\n",
    "print(\"Soybean dataset distribution: \", soybean_data_distribution)\n",
    "soybean_data_distribution.append(soybean_data_size)\n",
    "\n",
    "print(\"\\nOther dataset size: \", other_data_size)\n",
    "print(\"Other dataset distribution: \", other_data_distribution)\n",
    "other_data_distribution.append(other_data_size)\n",
    "\n",
    "print()\n",
    "data_table = np.array([data_distribution, corn_data_distribution, soybean_data_distribution, other_data_distribution])\n",
    "\n",
    "dtf = pd.DataFrame(data_table)\n",
    "dtf.index = [\"Full dataset\", \"Corn Dataset\", \"Soybean Dataset\", \"Other Dataset\"]\n",
    "dtf.columns = [\"Grass\", \"High tillage\", \"Low tillage\", \"No tillage\", \"Datasize\"]\n",
    "print(dtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_key = list(corn_data)\n",
    "corn_train, corn_other = train_test_split(corn_key, test_size=0.3)\n",
    "corn_val, corn_test = train_test_split(corn_other, test_size = 0.5)\n",
    "corn_dataset = {\n",
    "    \"train\": corn_train,\n",
    "    \"val\": corn_val,\n",
    "    \"test\": corn_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_key = list(soybean_data)\n",
    "soybean_train, soybean_other = train_test_split(soybean_key, test_size=0.3)\n",
    "soybean_val, soybean_test = train_test_split(soybean_other, test_size = 0.5)\n",
    "soybean_dataset = {\n",
    "    \"train\": soybean_train,\n",
    "    \"val\": soybean_val,\n",
    "    \"test\": soybean_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages2(main_dir, type, crop_dataset, crop_data):\n",
    "\n",
    "    dir = main_dir + \"_image/\"\n",
    "    # gdir = main_dir + \"_geotagging/\"\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "\n",
    "\n",
    "    image_dir = main_dir + \"_image/\" + type + \"_dataset\"\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.mkdir(image_dir)\n",
    "    else:\n",
    "        print(\"Directory already exists\")\n",
    "        return\n",
    "\n",
    "    for phase in [\"train\", \"val\", \"test\"]:\n",
    "        dataset = crop_dataset[phase]\n",
    "        for path in dataset:\n",
    "            info = crop_data[path]\n",
    "            file_name, tillage_type = info\n",
    "\n",
    "            image_dir_phase = image_dir + \"/\" + phase\n",
    "\n",
    "            if not os.path.exists(image_dir_phase):\n",
    "                os.mkdir(image_dir_phase)\n",
    "            \n",
    "\n",
    "            if info[1] == 0:\n",
    "                image_dir_phase += \"/high_tillage/\"\n",
    "            elif info[1] == 1:\n",
    "                image_dir_phase += \"/low_tillage/\"\n",
    "            elif info[1] == 2:\n",
    "                image_dir_phase += \"/no_tillage/\"\n",
    "            elif info[1] == 3:\n",
    "                image_dir_phase += \"/grass/\"\n",
    "\n",
    "            if not os.path.exists(image_dir_phase):\n",
    "                os.mkdir(image_dir_phase)\n",
    "                        \n",
    "            image_dir_phase += file_name\n",
    "\n",
    "            image = Image.open(\"ground_truth_analysis/ground_truth/\" + path)\n",
    "\n",
    "            image.save(image_dir_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "processImages2(\"ground_truth_analysis\", \"corn\", corn_dataset, corn_data)\n",
    "processImages2(\"ground_truth_analysis\", \"soybean\", soybean_dataset, soybean_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
