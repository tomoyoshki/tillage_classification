{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "import geopandas as gp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_width, img_height = 5184, 3888\n",
    "\n",
    "IMAGE_DIRECTORY = \"StreetviewImages/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prev/confidence_data.pickle\", \"rb\") as f:\n",
    "    data = np.array(pickle.load(f))\n",
    "full_dataset = dict((data[i][0], [data[i][3], data[i][4]]) for i in range(data.shape[0]))\n",
    "mask_map = data[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geotagging Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geotag(path, mask_path, min_height = 5400, center_only = False):\n",
    "    image = Image.open(path)\n",
    "    image = np.array(image)\n",
    "\n",
    "    # Geotagging\n",
    "    mask = np.zeros([img_height, img_width])\n",
    "    df = gp.read_file(mask_path)\n",
    "    for poly in df['geometry']:\n",
    "        x, y = poly.exterior.coords.xy\n",
    "        polygon = [(x, y) for x, y in zip(x, y)]\n",
    "        img = Image.new('L', (img_width, img_height), 0)\n",
    "        ImageDraw.Draw(img).polygon(polygon, outline=1, fill=1)\n",
    "\n",
    "        poly_mask = np.array(img)\n",
    "        poly_mask = np.reshape(poly_mask, mask.shape)\n",
    "\n",
    "        mask = np.logical_or(mask, poly_mask)\n",
    "\n",
    "\n",
    "    mask = mask.astype(np.float)\n",
    "\n",
    "    if center_only:\n",
    "        get the image part only, discard the black part\n",
    "        start_row = -1\n",
    "        end_row = mask.shape[0]\n",
    "        for i in range(0, mask.shape[0]):\n",
    "            if mask[i].any() > 0 and start_row == -1:\n",
    "                start_row = i\n",
    "            elif mask[i].any() == 0 and start_row != -1:\n",
    "                end_row = i + 1\n",
    "                break\n",
    "\n",
    "    for i in range(0, mask.shape[0]):\n",
    "        if mask[i].any() != 0:\n",
    "            continue\n",
    "        else:\n",
    "            image[i, :, :] = 0\n",
    "\n",
    "    if center_only:\n",
    "        if end_row - start_row < min_height:\n",
    "            min_height = end_row - start_row\n",
    "        image = image[start_row:end_row, :, :]\n",
    "        mask = np.stack([mask, mask, mask], axis=2)\n",
    "        new_img = image * mask\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read images from the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  908\n",
      "Dataset distribution:  [291, 329, 111, 177]\n",
      "\n",
      "Corn dataset size:  395\n",
      "Corn dataset distribution:  [78, 199, 73, 45]\n",
      "\n",
      "Soybean dataset size:  346\n",
      "Soybean dataset distribution:  [171, 84, 17, 74]\n",
      "\n",
      "Other dataset size:  167\n",
      "Other dataset distribution:  [42, 46, 21, 58]\n",
      "\n",
      "                 High tillage  Low tillage  No tillage  Grass  Datasize\n",
      "Full dataset              291          329         111    177       908\n",
      "Corn Dataset               78          199          73     45       395\n",
      "Soybean Dataset           171           84          17     74       346\n",
      "Other Dataset              42           46          21     58       167\n"
     ]
    }
   ],
   "source": [
    "data_size = 0\n",
    "corn_data_size = 0\n",
    "soybean_data_size = 0\n",
    "other_data_size = 0\n",
    "\n",
    "data_distribution = [0, 0, 0, 0]\n",
    "corn_data_distribution = [0, 0, 0, 0]\n",
    "soybean_data_distribution = [0, 0, 0, 0]\n",
    "other_data_distribution = [0, 0, 0, 0]\n",
    "\n",
    "corn_data = {}\n",
    "soybean_data = {}\n",
    "other_data = {}\n",
    "\n",
    "for folders in os.listdir(IMAGE_DIRECTORY):\n",
    "    for files in os.listdir(IMAGE_DIRECTORY + folders):\n",
    "        path = IMAGE_DIRECTORY + folders + \"/\" + files\n",
    "\n",
    "        mask_path = \"StreetviewBoundaries/\" + folders + \"/\" + files + \".geojson\"\n",
    "        if os.path.exists(path) and os.path.exists(mask_path) and path in full_dataset.keys() and mask_path in mask_map:\n",
    "            data_size += 1\n",
    "\n",
    "            info = full_dataset[path]\n",
    "            info.append(mask_path)\n",
    "            info.append(files)\n",
    "            data_distribution[info[1]] += 1\n",
    "\n",
    "            if info[0] == 5:\n",
    "                soybean_data_size += 1\n",
    "                soybean_data_distribution[info[1]] += 1\n",
    "                soybean_data[path] = info\n",
    "            elif info[0] == 1:\n",
    "                corn_data_size += 1\n",
    "                corn_data_distribution[info[1]] += 1\n",
    "                corn_data[path] = info\n",
    "            else:\n",
    "                other_data_size += 1\n",
    "                other_data_distribution[info[1]] += 1\n",
    "                other_data[path] = info\n",
    "\n",
    "\n",
    "print(\"Dataset size: \", data_size)\n",
    "print(\"Dataset distribution: \", data_distribution)\n",
    "data_distribution.append(data_size)\n",
    "\n",
    "print(\"\\nCorn dataset size: \", corn_data_size)\n",
    "print(\"Corn dataset distribution: \", corn_data_distribution)\n",
    "corn_data_distribution.append(corn_data_size)\n",
    "\n",
    "print(\"\\nSoybean dataset size: \", soybean_data_size)\n",
    "print(\"Soybean dataset distribution: \", soybean_data_distribution)\n",
    "soybean_data_distribution.append(soybean_data_size)\n",
    "\n",
    "print(\"\\nOther dataset size: \", other_data_size)\n",
    "print(\"Other dataset distribution: \", other_data_distribution)\n",
    "other_data_distribution.append(other_data_size)\n",
    "\n",
    "print()\n",
    "data_table = np.array([data_distribution, corn_data_distribution, soybean_data_distribution, other_data_distribution])\n",
    "\n",
    "dtf = pd.DataFrame(data_table)\n",
    "dtf.index = [\"Full dataset\", \"Corn Dataset\", \"Soybean Dataset\", \"Other Dataset\"]\n",
    "dtf.columns = [\"High tillage\", \"Low tillage\", \"No tillage\", \"Grass\", \"Datasize\"]\n",
    "print(dtf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Crop Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_key = list(corn_data)\n",
    "corn_train, corn_other = train_test_split(corn_key, test_size=0.3)\n",
    "corn_val, corn_test = train_test_split(corn_other, test_size = 0.5)\n",
    "corn_dataset = {\n",
    "    \"train\": corn_train,\n",
    "    \"val\": corn_val,\n",
    "    \"test\": corn_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soybean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "soybean_key = list(soybean_data)\n",
    "soybean_train, soybean_other = train_test_split(soybean_key, test_size=0.3)\n",
    "soybean_val, soybean_test = train_test_split(soybean_other, test_size = 0.5)\n",
    "soybean_dataset = {\n",
    "    \"train\": soybean_train,\n",
    "    \"val\": soybean_val,\n",
    "    \"test\": soybean_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_image(image_dir, geotagging_dir, phase, path, info):\n",
    "    crop_type, tillage_type, mask_path, file_name = info\n",
    "\n",
    "    image_dir_phase = image_dir + \"/\" + phase\n",
    "    geotagging_dir_phase = geotagging_dir + \"/\" + phase\n",
    "\n",
    "    if not os.path.exists(image_dir_phase):\n",
    "        os.mkdir(image_dir_phase)\n",
    "    \n",
    "    if not os.path.exists(geotagging_dir_phase):\n",
    "        os.mkdir(geotagging_dir_phase)\n",
    "\n",
    "    tillage_dict = {\n",
    "        0: \"/high_tillage/\",\n",
    "        1: \"/low_tillage/\",\n",
    "        2: \"/no_tillage/\",\n",
    "        3: \"/grass/\"\n",
    "    }\n",
    "\n",
    "    image_dir_phase += tillage_dict[tillage_type]\n",
    "    geotagging_dir_phase += tillage_dict[tillage_type]\n",
    "    \n",
    "    if not os.path.exists(geotagging_dir_phase):\n",
    "        os.mkdir(geotagging_dir_phase)\n",
    "    \n",
    "    image_dir_phase += file_name\n",
    "    geotagging_dir_phase += file_name\n",
    "\n",
    "    image = Image.open(path)\n",
    "    geotagging_image = geotag(path, mask_path)\n",
    "\n",
    "    image.save(image_dir_phase)\n",
    "    geotagging_image.save(geotagging_dir_phase) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages(main_dir, type, crop_dataset, crop_data):\n",
    "    '''\n",
    "    Stores images by train, val, test, and crop type\n",
    "    '''\n",
    "\n",
    "    dir = main_dir + \"_image/\"\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "\n",
    "    image_dir = main_dir + \"_image/\" + type + \"_dataset\"\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.mkdir(image_dir)\n",
    "    else:\n",
    "        print(\"Directory already exists\")\n",
    "        return\n",
    "\n",
    "    for phase in [\"train\", \"val\", \"test\"]:\n",
    "        dataset = crop_dataset[phase]\n",
    "        for path in dataset:\n",
    "            info = crop_data[path]\n",
    "            crop_type, tillage_type, mask_path, file_name = info\n",
    "\n",
    "            image_dir_phase = image_dir + \"/\" + phase\n",
    "\n",
    "            if not os.path.exists(image_dir_phase):\n",
    "                os.mkdir(image_dir_phase)\n",
    "            \n",
    "            if info[1] == 0:\n",
    "                image_dir_phase += \"/high_tillage/\"\n",
    "            elif info[1] == 1:\n",
    "                image_dir_phase += \"/low_tillage/\"\n",
    "            elif info[1] == 2:\n",
    "                image_dir_phase += \"/no_tillage/\"\n",
    "            elif info[1] == 3:\n",
    "                image_dir_phase += \"/grass/\"\n",
    "\n",
    "            if not os.path.exists(image_dir_phase):\n",
    "                os.mkdir(image_dir_phase)\n",
    "            \n",
    "            \n",
    "            image_dir_phase += file_name\n",
    "\n",
    "            image = Image.open(path)\n",
    "            # geotagging_image = geotag(path, mask_path)\n",
    "\n",
    "            image.save(image_dir_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "processImages(\"TARGET_DIR\", \"corn\", corn_dataset, corn_data)\n",
    "processImages(\"TARGET_DIR\", \"soybean\", corn_dataset, corn_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
